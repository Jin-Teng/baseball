{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#讀黨\n",
    "import numpy as np\n",
    "x_train = np.loadtxt('x_train.csv', delimiter=',')\n",
    "x_test = np.loadtxt('X_test.csv', delimiter=',')\n",
    "y_train= np.loadtxt('y_train.csv', delimiter=',')\n",
    "y_test = np.loadtxt('y_test.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 25.,  27.,  37.,  49.,  70.,  73.,  79.,  69.,  47.,  35.,   3.,\n",
       "          3.,   1.,   1.,   1.]),\n",
       " array([ 0,  5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75]),\n",
       " <a list of 15 Patch objects>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEACAYAAACj0I2EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1AgLXZIaYaFLUiP+H49SWv0nzzIsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6dcc6a550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#開始觀察資料決定區間\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "bins = np.arange(0, 80,5)\n",
    "plt.hist(y_train, bins = bins, alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.453846153846154"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.728895981168526"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#轉變Ｘ的型態\n",
    "X = np.reshape(x_train,(520,15,1))#(x_train的個數, 15, 1)\n",
    "X_test = np.reshape(x_test,(264,15,1))#(x_test的個數, 15, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  23.],\n",
       "        [  12.],\n",
       "        [   6.],\n",
       "        ..., \n",
       "        [   2.],\n",
       "        [  11.],\n",
       "        [   1.]],\n",
       "\n",
       "       [[  24.],\n",
       "        [   9.],\n",
       "        [  18.],\n",
       "        ..., \n",
       "        [   4.],\n",
       "        [  79.],\n",
       "        [   5.]],\n",
       "\n",
       "       [[  25.],\n",
       "        [ 105.],\n",
       "        [ 357.],\n",
       "        ..., \n",
       "        [  45.],\n",
       "        [  71.],\n",
       "        [ 136.]],\n",
       "\n",
       "       ..., \n",
       "       [[  27.],\n",
       "        [ 162.],\n",
       "        [ 714.],\n",
       "        ..., \n",
       "        [ 121.],\n",
       "        [ 116.],\n",
       "        [ 288.]],\n",
       "\n",
       "       [[  28.],\n",
       "        [ 161.],\n",
       "        [ 701.],\n",
       "        ..., \n",
       "        [ 107.],\n",
       "        [ 154.],\n",
       "        [ 370.]],\n",
       "\n",
       "       [[  29.],\n",
       "        [ 158.],\n",
       "        [ 685.],\n",
       "        ..., \n",
       "        [ 112.],\n",
       "        [ 154.],\n",
       "        [ 325.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#輸出這邊我將資料分成群\n",
    "y_train[y_train<15] = 0\n",
    "y_train[(y_train>=15) & (y_train<25)] = 1\n",
    "y_train[(y_train>=25) & (y_train<35)] = 2\n",
    "y_train[(y_train>=35) & (y_train<45)] = 3\n",
    "y_train[(y_train>=45)] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test[y_test<15] = 0\n",
    "y_test[(y_test>=15) & (y_test<25)] = 1\n",
    "y_test[(y_test>=25) & (y_test<35)] = 2\n",
    "y_test[(y_test>=35) & (y_test<45)] = 3\n",
    "y_test[(y_test>=45)] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#將Ｙ轉換型態\n",
    "from keras.utils import np_utils\n",
    "y_train_trans = np_utils.to_categorical(y_train,5)\n",
    "y_test_trans = np_utils.to_categorical(y_test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 256)               264192    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 265,477.0\n",
      "Trainable params: 265,477.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation, LSTM, Dropout\n",
    "from keras.optimizers import SGD\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, activation=\"sigmoid\", input_shape=(X.shape[1], X.shape[2]), recurrent_dropout=0.2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y_train_trans.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 520 samples, validate on 264 samples\n",
      "Epoch 1/200\n",
      "520/520 [==============================] - 1s - loss: 1.3459 - acc: 0.3808 - val_loss: 1.4955 - val_acc: 0.2992\n",
      "Epoch 2/200\n",
      "520/520 [==============================] - 1s - loss: 1.3411 - acc: 0.4000 - val_loss: 1.5002 - val_acc: 0.3144\n",
      "Epoch 3/200\n",
      "520/520 [==============================] - 2s - loss: 1.3342 - acc: 0.4173 - val_loss: 1.6292 - val_acc: 0.2689\n",
      "Epoch 4/200\n",
      "520/520 [==============================] - 2s - loss: 1.3319 - acc: 0.3865 - val_loss: 1.5834 - val_acc: 0.2727\n",
      "Epoch 5/200\n",
      "520/520 [==============================] - 2s - loss: 1.3280 - acc: 0.4096 - val_loss: 1.5026 - val_acc: 0.2879\n",
      "Epoch 6/200\n",
      "520/520 [==============================] - 2s - loss: 1.3347 - acc: 0.4135 - val_loss: 1.5248 - val_acc: 0.2841\n",
      "Epoch 7/200\n",
      "520/520 [==============================] - 2s - loss: 1.3293 - acc: 0.3981 - val_loss: 1.4651 - val_acc: 0.3258\n",
      "Epoch 8/200\n",
      "520/520 [==============================] - 2s - loss: 1.3290 - acc: 0.3981 - val_loss: 1.5200 - val_acc: 0.3030\n",
      "Epoch 9/200\n",
      "520/520 [==============================] - 3s - loss: 1.3163 - acc: 0.4154 - val_loss: 1.5478 - val_acc: 0.2879\n",
      "Epoch 10/200\n",
      "520/520 [==============================] - 3s - loss: 1.3345 - acc: 0.4154 - val_loss: 1.6118 - val_acc: 0.2803\n",
      "Epoch 11/200\n",
      "520/520 [==============================] - 3s - loss: 1.3273 - acc: 0.4154 - val_loss: 1.5312 - val_acc: 0.3030\n",
      "Epoch 12/200\n",
      "520/520 [==============================] - 3s - loss: 1.3276 - acc: 0.4058 - val_loss: 1.5567 - val_acc: 0.2955\n",
      "Epoch 13/200\n",
      "520/520 [==============================] - 3s - loss: 1.3175 - acc: 0.3904 - val_loss: 1.5092 - val_acc: 0.2992\n",
      "Epoch 14/200\n",
      "520/520 [==============================] - 2s - loss: 1.2996 - acc: 0.4154 - val_loss: 1.5894 - val_acc: 0.2841\n",
      "Epoch 15/200\n",
      "520/520 [==============================] - 3s - loss: 1.3134 - acc: 0.4038 - val_loss: 1.5127 - val_acc: 0.3144\n",
      "Epoch 16/200\n",
      "520/520 [==============================] - 3s - loss: 1.3231 - acc: 0.4115 - val_loss: 1.4848 - val_acc: 0.3144\n",
      "Epoch 17/200\n",
      "520/520 [==============================] - 3s - loss: 1.3352 - acc: 0.4019 - val_loss: 1.4740 - val_acc: 0.3068\n",
      "Epoch 18/200\n",
      "520/520 [==============================] - 2s - loss: 1.3050 - acc: 0.4346 - val_loss: 1.5853 - val_acc: 0.2727\n",
      "Epoch 19/200\n",
      "520/520 [==============================] - 2s - loss: 1.3283 - acc: 0.3865 - val_loss: 1.5609 - val_acc: 0.2955\n",
      "Epoch 20/200\n",
      "520/520 [==============================] - 2s - loss: 1.3195 - acc: 0.3923 - val_loss: 1.5246 - val_acc: 0.2879\n",
      "Epoch 21/200\n",
      "520/520 [==============================] - 3s - loss: 1.2936 - acc: 0.4500 - val_loss: 1.5845 - val_acc: 0.2538\n",
      "Epoch 22/200\n",
      "520/520 [==============================] - 3s - loss: 1.3032 - acc: 0.4115 - val_loss: 1.6515 - val_acc: 0.2652\n",
      "Epoch 23/200\n",
      "520/520 [==============================] - 2s - loss: 1.3070 - acc: 0.4058 - val_loss: 1.6596 - val_acc: 0.2500\n",
      "Epoch 24/200\n",
      "520/520 [==============================] - 2s - loss: 1.3019 - acc: 0.4135 - val_loss: 1.5007 - val_acc: 0.3220\n",
      "Epoch 25/200\n",
      "520/520 [==============================] - 3s - loss: 1.2914 - acc: 0.4173 - val_loss: 1.5211 - val_acc: 0.3068\n",
      "Epoch 26/200\n",
      "520/520 [==============================] - 3s - loss: 1.2996 - acc: 0.4077 - val_loss: 1.5244 - val_acc: 0.2841\n",
      "Epoch 27/200\n",
      "520/520 [==============================] - 2s - loss: 1.3119 - acc: 0.4231 - val_loss: 1.5104 - val_acc: 0.3106\n",
      "Epoch 28/200\n",
      "520/520 [==============================] - 3s - loss: 1.3335 - acc: 0.3885 - val_loss: 1.5795 - val_acc: 0.2765\n",
      "Epoch 29/200\n",
      "520/520 [==============================] - 3s - loss: 1.2897 - acc: 0.4346 - val_loss: 1.5723 - val_acc: 0.2879\n",
      "Epoch 30/200\n",
      "520/520 [==============================] - 3s - loss: 1.3113 - acc: 0.4288 - val_loss: 1.6373 - val_acc: 0.2462\n",
      "Epoch 31/200\n",
      "520/520 [==============================] - 3s - loss: 1.3101 - acc: 0.4019 - val_loss: 1.6275 - val_acc: 0.2879\n",
      "Epoch 32/200\n",
      "520/520 [==============================] - 3s - loss: 1.3088 - acc: 0.3981 - val_loss: 1.5001 - val_acc: 0.2992\n",
      "Epoch 33/200\n",
      "520/520 [==============================] - 3s - loss: 1.2933 - acc: 0.4192 - val_loss: 1.6498 - val_acc: 0.2538\n",
      "Epoch 34/200\n",
      "520/520 [==============================] - 3s - loss: 1.3148 - acc: 0.4096 - val_loss: 1.5456 - val_acc: 0.2727\n",
      "Epoch 35/200\n",
      "520/520 [==============================] - 3s - loss: 1.2849 - acc: 0.4346 - val_loss: 1.5047 - val_acc: 0.3068\n",
      "Epoch 36/200\n",
      "520/520 [==============================] - 3s - loss: 1.2749 - acc: 0.4365 - val_loss: 1.5251 - val_acc: 0.3106\n",
      "Epoch 37/200\n",
      "520/520 [==============================] - 2s - loss: 1.2993 - acc: 0.4038 - val_loss: 1.5640 - val_acc: 0.2917\n",
      "Epoch 38/200\n",
      "520/520 [==============================] - 2s - loss: 1.2977 - acc: 0.4346 - val_loss: 1.5606 - val_acc: 0.3030\n",
      "Epoch 39/200\n",
      "520/520 [==============================] - 2s - loss: 1.3255 - acc: 0.4038 - val_loss: 1.6786 - val_acc: 0.2727\n",
      "Epoch 40/200\n",
      "520/520 [==============================] - 2s - loss: 1.2906 - acc: 0.4288 - val_loss: 1.5750 - val_acc: 0.3182\n",
      "Epoch 41/200\n",
      "520/520 [==============================] - 2s - loss: 1.2832 - acc: 0.4346 - val_loss: 1.5362 - val_acc: 0.2765\n",
      "Epoch 42/200\n",
      "520/520 [==============================] - 2s - loss: 1.2942 - acc: 0.4327 - val_loss: 1.5870 - val_acc: 0.2652\n",
      "Epoch 43/200\n",
      "520/520 [==============================] - 2s - loss: 1.3075 - acc: 0.3962 - val_loss: 1.4813 - val_acc: 0.3333\n",
      "Epoch 44/200\n",
      "520/520 [==============================] - 1s - loss: 1.2905 - acc: 0.4231 - val_loss: 1.6169 - val_acc: 0.2689\n",
      "Epoch 45/200\n",
      "520/520 [==============================] - 2s - loss: 1.2736 - acc: 0.4154 - val_loss: 1.5392 - val_acc: 0.2841\n",
      "Epoch 46/200\n",
      "520/520 [==============================] - 2s - loss: 1.2565 - acc: 0.4500 - val_loss: 1.5370 - val_acc: 0.3220\n",
      "Epoch 47/200\n",
      "520/520 [==============================] - 2s - loss: 1.2564 - acc: 0.4288 - val_loss: 1.6090 - val_acc: 0.2955\n",
      "Epoch 48/200\n",
      "520/520 [==============================] - 2s - loss: 1.2783 - acc: 0.4173 - val_loss: 1.5942 - val_acc: 0.2689\n",
      "Epoch 49/200\n",
      "520/520 [==============================] - 2s - loss: 1.2769 - acc: 0.4500 - val_loss: 1.5343 - val_acc: 0.3258\n",
      "Epoch 50/200\n",
      "520/520 [==============================] - 2s - loss: 1.2604 - acc: 0.4558 - val_loss: 1.6442 - val_acc: 0.2803\n",
      "Epoch 51/200\n",
      "520/520 [==============================] - 2s - loss: 1.2765 - acc: 0.4481 - val_loss: 1.5789 - val_acc: 0.2992\n",
      "Epoch 52/200\n",
      "520/520 [==============================] - 2s - loss: 1.2831 - acc: 0.4462 - val_loss: 1.5357 - val_acc: 0.2955\n",
      "Epoch 53/200\n",
      "520/520 [==============================] - 2s - loss: 1.2689 - acc: 0.4635 - val_loss: 1.5201 - val_acc: 0.3182\n",
      "Epoch 54/200\n",
      "520/520 [==============================] - 2s - loss: 1.2617 - acc: 0.4385 - val_loss: 1.5546 - val_acc: 0.2803\n",
      "Epoch 55/200\n",
      "520/520 [==============================] - 2s - loss: 1.2770 - acc: 0.4000 - val_loss: 1.6200 - val_acc: 0.2727\n",
      "Epoch 56/200\n",
      "520/520 [==============================] - 2s - loss: 1.2501 - acc: 0.4577 - val_loss: 1.6337 - val_acc: 0.2765\n",
      "Epoch 57/200\n",
      "520/520 [==============================] - 2s - loss: 1.2646 - acc: 0.4442 - val_loss: 1.5484 - val_acc: 0.3030\n",
      "Epoch 58/200\n",
      "520/520 [==============================] - 2s - loss: 1.2610 - acc: 0.4596 - val_loss: 1.5745 - val_acc: 0.2992\n",
      "Epoch 59/200\n",
      "520/520 [==============================] - 2s - loss: 1.2403 - acc: 0.4462 - val_loss: 1.5297 - val_acc: 0.3409\n",
      "Epoch 60/200\n",
      "520/520 [==============================] - 2s - loss: 1.2373 - acc: 0.4596 - val_loss: 1.5478 - val_acc: 0.3144\n",
      "Epoch 61/200\n",
      "520/520 [==============================] - 2s - loss: 1.2760 - acc: 0.4577 - val_loss: 1.6087 - val_acc: 0.2727\n",
      "Epoch 62/200\n",
      "520/520 [==============================] - 2s - loss: 1.2534 - acc: 0.4423 - val_loss: 1.5638 - val_acc: 0.2992\n",
      "Epoch 63/200\n",
      "520/520 [==============================] - 2s - loss: 1.2435 - acc: 0.4731 - val_loss: 1.5801 - val_acc: 0.3220\n",
      "Epoch 64/200\n",
      "520/520 [==============================] - 2s - loss: 1.2615 - acc: 0.4519 - val_loss: 1.5342 - val_acc: 0.3182\n",
      "Epoch 65/200\n",
      "520/520 [==============================] - 2s - loss: 1.2396 - acc: 0.4615 - val_loss: 1.5811 - val_acc: 0.3295\n",
      "Epoch 66/200\n",
      "520/520 [==============================] - 2s - loss: 1.2541 - acc: 0.4385 - val_loss: 1.5935 - val_acc: 0.3068\n",
      "Epoch 67/200\n",
      "520/520 [==============================] - 2s - loss: 1.2376 - acc: 0.4500 - val_loss: 1.5674 - val_acc: 0.3295\n",
      "Epoch 68/200\n",
      "520/520 [==============================] - 2s - loss: 1.2446 - acc: 0.4538 - val_loss: 1.5749 - val_acc: 0.3220\n",
      "Epoch 69/200\n",
      "520/520 [==============================] - 2s - loss: 1.2475 - acc: 0.4308 - val_loss: 1.5345 - val_acc: 0.3295\n",
      "Epoch 70/200\n",
      "520/520 [==============================] - 2s - loss: 1.2451 - acc: 0.4519 - val_loss: 1.5899 - val_acc: 0.3068\n",
      "Epoch 71/200\n",
      "520/520 [==============================] - 2s - loss: 1.2235 - acc: 0.4481 - val_loss: 1.5749 - val_acc: 0.3258\n",
      "Epoch 72/200\n",
      "520/520 [==============================] - 2s - loss: 1.2418 - acc: 0.4423 - val_loss: 1.6214 - val_acc: 0.2917\n",
      "Epoch 73/200\n",
      "520/520 [==============================] - 2s - loss: 1.2465 - acc: 0.4538 - val_loss: 1.5759 - val_acc: 0.3144\n",
      "Epoch 74/200\n",
      "520/520 [==============================] - 2s - loss: 1.2204 - acc: 0.4615 - val_loss: 1.5874 - val_acc: 0.3333\n",
      "Epoch 75/200\n",
      "520/520 [==============================] - 2s - loss: 1.2488 - acc: 0.4442 - val_loss: 1.5750 - val_acc: 0.3295\n",
      "Epoch 76/200\n",
      "520/520 [==============================] - 2s - loss: 1.2231 - acc: 0.4769 - val_loss: 1.6125 - val_acc: 0.3371\n",
      "Epoch 77/200\n",
      "520/520 [==============================] - 2s - loss: 1.2296 - acc: 0.4769 - val_loss: 1.6252 - val_acc: 0.2955\n",
      "Epoch 78/200\n",
      "520/520 [==============================] - 2s - loss: 1.2139 - acc: 0.4673 - val_loss: 1.6352 - val_acc: 0.3106\n",
      "Epoch 79/200\n",
      "520/520 [==============================] - 2s - loss: 1.2487 - acc: 0.4596 - val_loss: 1.6395 - val_acc: 0.3030\n",
      "Epoch 80/200\n",
      "520/520 [==============================] - 2s - loss: 1.2307 - acc: 0.4942 - val_loss: 1.6047 - val_acc: 0.2879\n",
      "Epoch 81/200\n",
      "520/520 [==============================] - 2s - loss: 1.2204 - acc: 0.4827 - val_loss: 1.5820 - val_acc: 0.3371\n",
      "Epoch 82/200\n",
      "520/520 [==============================] - 2s - loss: 1.2164 - acc: 0.4577 - val_loss: 1.5921 - val_acc: 0.2992\n",
      "Epoch 83/200\n",
      "520/520 [==============================] - 2s - loss: 1.1998 - acc: 0.4519 - val_loss: 1.6208 - val_acc: 0.3561\n",
      "Epoch 84/200\n",
      "520/520 [==============================] - 2s - loss: 1.2317 - acc: 0.4577 - val_loss: 1.5889 - val_acc: 0.3333\n",
      "Epoch 85/200\n",
      "520/520 [==============================] - 2s - loss: 1.2186 - acc: 0.4615 - val_loss: 1.6123 - val_acc: 0.3409\n",
      "Epoch 86/200\n",
      "520/520 [==============================] - 2s - loss: 1.2154 - acc: 0.4808 - val_loss: 1.5581 - val_acc: 0.3409\n",
      "Epoch 87/200\n",
      "520/520 [==============================] - 2s - loss: 1.2248 - acc: 0.4692 - val_loss: 1.5559 - val_acc: 0.3220\n",
      "Epoch 88/200\n",
      "520/520 [==============================] - 2s - loss: 1.2162 - acc: 0.4654 - val_loss: 1.5072 - val_acc: 0.3523\n",
      "Epoch 89/200\n",
      "520/520 [==============================] - 2s - loss: 1.2076 - acc: 0.4365 - val_loss: 1.5981 - val_acc: 0.3295\n",
      "Epoch 90/200\n",
      "520/520 [==============================] - 2s - loss: 1.2179 - acc: 0.4750 - val_loss: 1.6397 - val_acc: 0.3258\n",
      "Epoch 91/200\n",
      "520/520 [==============================] - 2s - loss: 1.2302 - acc: 0.4385 - val_loss: 1.5714 - val_acc: 0.3333\n",
      "Epoch 92/200\n",
      "520/520 [==============================] - 2s - loss: 1.1975 - acc: 0.5115 - val_loss: 1.5409 - val_acc: 0.3220\n",
      "Epoch 93/200\n",
      "520/520 [==============================] - 2s - loss: 1.2114 - acc: 0.4481 - val_loss: 1.5320 - val_acc: 0.3371\n",
      "Epoch 94/200\n",
      "520/520 [==============================] - 2s - loss: 1.2220 - acc: 0.4404 - val_loss: 1.5833 - val_acc: 0.3182\n",
      "Epoch 95/200\n",
      "520/520 [==============================] - 2s - loss: 1.2265 - acc: 0.4346 - val_loss: 1.5456 - val_acc: 0.3258\n",
      "Epoch 96/200\n",
      "520/520 [==============================] - 2s - loss: 1.2259 - acc: 0.4385 - val_loss: 1.5469 - val_acc: 0.3220\n",
      "Epoch 97/200\n",
      "520/520 [==============================] - 2s - loss: 1.1893 - acc: 0.4904 - val_loss: 1.6214 - val_acc: 0.3333\n",
      "Epoch 98/200\n",
      "520/520 [==============================] - 2s - loss: 1.1802 - acc: 0.4750 - val_loss: 1.6150 - val_acc: 0.3371\n",
      "Epoch 99/200\n",
      "520/520 [==============================] - 2s - loss: 1.2155 - acc: 0.4731 - val_loss: 1.6380 - val_acc: 0.3068\n",
      "Epoch 100/200\n",
      "520/520 [==============================] - 2s - loss: 1.2055 - acc: 0.4654 - val_loss: 1.6067 - val_acc: 0.3371\n",
      "Epoch 101/200\n",
      "520/520 [==============================] - 2s - loss: 1.2095 - acc: 0.4750 - val_loss: 1.5947 - val_acc: 0.3409\n",
      "Epoch 102/200\n",
      "520/520 [==============================] - 2s - loss: 1.1939 - acc: 0.4904 - val_loss: 1.6192 - val_acc: 0.3182\n",
      "Epoch 103/200\n",
      "520/520 [==============================] - 2s - loss: 1.2204 - acc: 0.4635 - val_loss: 1.6102 - val_acc: 0.3485\n",
      "Epoch 104/200\n",
      "520/520 [==============================] - 2s - loss: 1.1842 - acc: 0.4673 - val_loss: 1.6387 - val_acc: 0.3485\n",
      "Epoch 105/200\n",
      "520/520 [==============================] - 2s - loss: 1.1795 - acc: 0.4519 - val_loss: 1.6386 - val_acc: 0.3258\n",
      "Epoch 106/200\n",
      "520/520 [==============================] - 2s - loss: 1.1820 - acc: 0.4788 - val_loss: 1.5915 - val_acc: 0.3333\n",
      "Epoch 107/200\n",
      "520/520 [==============================] - 2s - loss: 1.1791 - acc: 0.5038 - val_loss: 1.6165 - val_acc: 0.3447\n",
      "Epoch 108/200\n",
      "520/520 [==============================] - 2s - loss: 1.1816 - acc: 0.4808 - val_loss: 1.6690 - val_acc: 0.3068\n",
      "Epoch 109/200\n",
      "520/520 [==============================] - 2s - loss: 1.1793 - acc: 0.4750 - val_loss: 1.6670 - val_acc: 0.3333\n",
      "Epoch 110/200\n",
      "520/520 [==============================] - 2s - loss: 1.1858 - acc: 0.4904 - val_loss: 1.6551 - val_acc: 0.3333\n",
      "Epoch 111/200\n",
      "520/520 [==============================] - 2s - loss: 1.1950 - acc: 0.4769 - val_loss: 1.6339 - val_acc: 0.3523\n",
      "Epoch 112/200\n",
      "520/520 [==============================] - 2s - loss: 1.1912 - acc: 0.4635 - val_loss: 1.6848 - val_acc: 0.3068\n",
      "Epoch 113/200\n",
      "520/520 [==============================] - 2s - loss: 1.1858 - acc: 0.4846 - val_loss: 1.6360 - val_acc: 0.3182\n",
      "Epoch 114/200\n",
      "520/520 [==============================] - 2s - loss: 1.1697 - acc: 0.4865 - val_loss: 1.6233 - val_acc: 0.3409\n",
      "Epoch 115/200\n",
      "520/520 [==============================] - 2s - loss: 1.1487 - acc: 0.5058 - val_loss: 1.6222 - val_acc: 0.3561\n",
      "Epoch 116/200\n",
      "520/520 [==============================] - 2s - loss: 1.1730 - acc: 0.5058 - val_loss: 1.6208 - val_acc: 0.3258\n",
      "Epoch 117/200\n",
      "520/520 [==============================] - 2s - loss: 1.1919 - acc: 0.4827 - val_loss: 1.6522 - val_acc: 0.3258\n",
      "Epoch 118/200\n",
      "520/520 [==============================] - 2s - loss: 1.1516 - acc: 0.5077 - val_loss: 1.6312 - val_acc: 0.3258\n",
      "Epoch 119/200\n",
      "520/520 [==============================] - 2s - loss: 1.1844 - acc: 0.4731 - val_loss: 1.6125 - val_acc: 0.3485\n",
      "Epoch 120/200\n",
      "520/520 [==============================] - 2s - loss: 1.1753 - acc: 0.5077 - val_loss: 1.6208 - val_acc: 0.3447\n",
      "Epoch 121/200\n",
      "520/520 [==============================] - 2s - loss: 1.1674 - acc: 0.5019 - val_loss: 1.6331 - val_acc: 0.3295\n",
      "Epoch 122/200\n",
      "520/520 [==============================] - 2s - loss: 1.1497 - acc: 0.4827 - val_loss: 1.6317 - val_acc: 0.3106\n",
      "Epoch 123/200\n",
      "520/520 [==============================] - 2s - loss: 1.1540 - acc: 0.5385 - val_loss: 1.7072 - val_acc: 0.3030\n",
      "Epoch 124/200\n",
      "520/520 [==============================] - 2s - loss: 1.1720 - acc: 0.4808 - val_loss: 1.6963 - val_acc: 0.3295\n",
      "Epoch 125/200\n",
      "520/520 [==============================] - 2s - loss: 1.1708 - acc: 0.4923 - val_loss: 1.6848 - val_acc: 0.3144\n",
      "Epoch 126/200\n",
      "520/520 [==============================] - 2s - loss: 1.1502 - acc: 0.5250 - val_loss: 1.6606 - val_acc: 0.3182\n",
      "Epoch 127/200\n",
      "520/520 [==============================] - 2s - loss: 1.1461 - acc: 0.5077 - val_loss: 1.6218 - val_acc: 0.3409\n",
      "Epoch 128/200\n",
      "520/520 [==============================] - 2s - loss: 1.1423 - acc: 0.4981 - val_loss: 1.6648 - val_acc: 0.3144\n",
      "Epoch 129/200\n",
      "520/520 [==============================] - 2s - loss: 1.1638 - acc: 0.5154 - val_loss: 1.6954 - val_acc: 0.3220\n",
      "Epoch 130/200\n",
      "520/520 [==============================] - 2s - loss: 1.1465 - acc: 0.5019 - val_loss: 1.6905 - val_acc: 0.3371\n",
      "Epoch 131/200\n",
      "520/520 [==============================] - 2s - loss: 1.1584 - acc: 0.5115 - val_loss: 1.7077 - val_acc: 0.3371\n",
      "Epoch 132/200\n",
      "520/520 [==============================] - 2s - loss: 1.1627 - acc: 0.4827 - val_loss: 1.6497 - val_acc: 0.3106\n",
      "Epoch 133/200\n",
      "520/520 [==============================] - 2s - loss: 1.1541 - acc: 0.5269 - val_loss: 1.7141 - val_acc: 0.3030\n",
      "Epoch 134/200\n",
      "520/520 [==============================] - 2s - loss: 1.1223 - acc: 0.5038 - val_loss: 1.8295 - val_acc: 0.3068\n",
      "Epoch 135/200\n",
      "520/520 [==============================] - 2s - loss: 1.1553 - acc: 0.5250 - val_loss: 1.6748 - val_acc: 0.3220\n",
      "Epoch 136/200\n",
      "520/520 [==============================] - 2s - loss: 1.1563 - acc: 0.4788 - val_loss: 1.7069 - val_acc: 0.3333\n",
      "Epoch 137/200\n",
      "520/520 [==============================] - 2s - loss: 1.1301 - acc: 0.4923 - val_loss: 1.7495 - val_acc: 0.3144\n",
      "Epoch 138/200\n",
      "520/520 [==============================] - 2s - loss: 1.1248 - acc: 0.4962 - val_loss: 1.6882 - val_acc: 0.3258\n",
      "Epoch 139/200\n",
      "520/520 [==============================] - 2s - loss: 1.1179 - acc: 0.5212 - val_loss: 1.6895 - val_acc: 0.3106\n",
      "Epoch 140/200\n",
      "520/520 [==============================] - 2s - loss: 1.1437 - acc: 0.5019 - val_loss: 1.6701 - val_acc: 0.3220\n",
      "Epoch 141/200\n",
      "520/520 [==============================] - 2s - loss: 1.1244 - acc: 0.5385 - val_loss: 1.7408 - val_acc: 0.3220\n",
      "Epoch 142/200\n",
      "520/520 [==============================] - 2s - loss: 1.1575 - acc: 0.5000 - val_loss: 1.6921 - val_acc: 0.3182\n",
      "Epoch 143/200\n",
      "520/520 [==============================] - 2s - loss: 1.1144 - acc: 0.5327 - val_loss: 1.6799 - val_acc: 0.3333\n",
      "Epoch 144/200\n",
      "520/520 [==============================] - 2s - loss: 1.1788 - acc: 0.5038 - val_loss: 1.7141 - val_acc: 0.3220\n",
      "Epoch 145/200\n",
      "520/520 [==============================] - 2s - loss: 1.1457 - acc: 0.4808 - val_loss: 1.7110 - val_acc: 0.3144\n",
      "Epoch 146/200\n",
      "520/520 [==============================] - 2s - loss: 1.1380 - acc: 0.5288 - val_loss: 1.6165 - val_acc: 0.3485\n",
      "Epoch 147/200\n",
      "520/520 [==============================] - 2s - loss: 1.1225 - acc: 0.5077 - val_loss: 1.6962 - val_acc: 0.3220\n",
      "Epoch 148/200\n",
      "520/520 [==============================] - 2s - loss: 1.1212 - acc: 0.5442 - val_loss: 1.6612 - val_acc: 0.3258\n",
      "Epoch 149/200\n",
      "520/520 [==============================] - 2s - loss: 1.1232 - acc: 0.5404 - val_loss: 1.6995 - val_acc: 0.3750\n",
      "Epoch 150/200\n",
      "520/520 [==============================] - 2s - loss: 1.1046 - acc: 0.5423 - val_loss: 1.7102 - val_acc: 0.3295\n",
      "Epoch 151/200\n",
      "520/520 [==============================] - 2s - loss: 1.1411 - acc: 0.4865 - val_loss: 1.6757 - val_acc: 0.3182\n",
      "Epoch 152/200\n",
      "520/520 [==============================] - 2s - loss: 1.1196 - acc: 0.5250 - val_loss: 1.6959 - val_acc: 0.3106\n",
      "Epoch 153/200\n",
      "520/520 [==============================] - 2s - loss: 1.1306 - acc: 0.5269 - val_loss: 1.6782 - val_acc: 0.3220\n",
      "Epoch 154/200\n",
      "520/520 [==============================] - 2s - loss: 1.1167 - acc: 0.5173 - val_loss: 1.7575 - val_acc: 0.3106\n",
      "Epoch 155/200\n",
      "520/520 [==============================] - 2s - loss: 1.1224 - acc: 0.5365 - val_loss: 1.7232 - val_acc: 0.3220\n",
      "Epoch 156/200\n",
      "520/520 [==============================] - 2s - loss: 1.1049 - acc: 0.5308 - val_loss: 1.7453 - val_acc: 0.3220\n",
      "Epoch 157/200\n",
      "520/520 [==============================] - 2s - loss: 1.1341 - acc: 0.5058 - val_loss: 1.7584 - val_acc: 0.3068\n",
      "Epoch 158/200\n",
      "520/520 [==============================] - 2s - loss: 1.1472 - acc: 0.5000 - val_loss: 1.6965 - val_acc: 0.3068\n",
      "Epoch 159/200\n",
      "520/520 [==============================] - 2s - loss: 1.1201 - acc: 0.5250 - val_loss: 1.7202 - val_acc: 0.3144\n",
      "Epoch 160/200\n",
      "520/520 [==============================] - 2s - loss: 1.0693 - acc: 0.5692 - val_loss: 1.7336 - val_acc: 0.3144\n",
      "Epoch 161/200\n",
      "520/520 [==============================] - 2s - loss: 1.0941 - acc: 0.5250 - val_loss: 1.7157 - val_acc: 0.3106\n",
      "Epoch 162/200\n",
      "520/520 [==============================] - 2s - loss: 1.0873 - acc: 0.5250 - val_loss: 1.7459 - val_acc: 0.3182\n",
      "Epoch 163/200\n",
      "520/520 [==============================] - 2s - loss: 1.1196 - acc: 0.5135 - val_loss: 1.7400 - val_acc: 0.3106\n",
      "Epoch 164/200\n",
      "520/520 [==============================] - 2s - loss: 1.1017 - acc: 0.5346 - val_loss: 1.7121 - val_acc: 0.3068\n",
      "Epoch 165/200\n",
      "520/520 [==============================] - 2s - loss: 1.1305 - acc: 0.5346 - val_loss: 1.8092 - val_acc: 0.3030\n",
      "Epoch 166/200\n",
      "520/520 [==============================] - 2s - loss: 1.1104 - acc: 0.5135 - val_loss: 1.7356 - val_acc: 0.3295\n",
      "Epoch 167/200\n",
      "520/520 [==============================] - 2s - loss: 1.1230 - acc: 0.5154 - val_loss: 1.7301 - val_acc: 0.3333\n",
      "Epoch 168/200\n",
      "520/520 [==============================] - 2s - loss: 1.0874 - acc: 0.5615 - val_loss: 1.7198 - val_acc: 0.3295\n",
      "Epoch 169/200\n",
      "520/520 [==============================] - 2s - loss: 1.0991 - acc: 0.5231 - val_loss: 1.6944 - val_acc: 0.3485\n",
      "Epoch 170/200\n",
      "520/520 [==============================] - 2s - loss: 1.1083 - acc: 0.5481 - val_loss: 1.7366 - val_acc: 0.3295\n",
      "Epoch 171/200\n",
      "520/520 [==============================] - 2s - loss: 1.1119 - acc: 0.5269 - val_loss: 1.7260 - val_acc: 0.3333\n",
      "Epoch 172/200\n",
      "520/520 [==============================] - 2s - loss: 1.0790 - acc: 0.5327 - val_loss: 1.7465 - val_acc: 0.3220\n",
      "Epoch 173/200\n",
      "520/520 [==============================] - 2s - loss: 1.0828 - acc: 0.5442 - val_loss: 1.7702 - val_acc: 0.3144\n",
      "Epoch 174/200\n",
      "520/520 [==============================] - 2s - loss: 1.0786 - acc: 0.5365 - val_loss: 1.8089 - val_acc: 0.3295\n",
      "Epoch 175/200\n",
      "520/520 [==============================] - 2s - loss: 1.0731 - acc: 0.5596 - val_loss: 1.7936 - val_acc: 0.3409\n",
      "Epoch 176/200\n",
      "520/520 [==============================] - 2s - loss: 1.1198 - acc: 0.5308 - val_loss: 1.7747 - val_acc: 0.3030\n",
      "Epoch 177/200\n",
      "520/520 [==============================] - 2s - loss: 1.1022 - acc: 0.5154 - val_loss: 1.7549 - val_acc: 0.3295\n",
      "Epoch 178/200\n",
      "520/520 [==============================] - 2s - loss: 1.1041 - acc: 0.5269 - val_loss: 1.7587 - val_acc: 0.3295\n",
      "Epoch 179/200\n",
      "520/520 [==============================] - 2s - loss: 1.0818 - acc: 0.5250 - val_loss: 1.7454 - val_acc: 0.3333\n",
      "Epoch 180/200\n",
      "520/520 [==============================] - 2s - loss: 1.0921 - acc: 0.5423 - val_loss: 1.8348 - val_acc: 0.3144\n",
      "Epoch 181/200\n",
      "520/520 [==============================] - 2s - loss: 1.0726 - acc: 0.5462 - val_loss: 1.7548 - val_acc: 0.3258\n",
      "Epoch 182/200\n",
      "520/520 [==============================] - 2s - loss: 1.0631 - acc: 0.5481 - val_loss: 1.7923 - val_acc: 0.3220\n",
      "Epoch 183/200\n",
      "520/520 [==============================] - 2s - loss: 1.0632 - acc: 0.5500 - val_loss: 1.8029 - val_acc: 0.3295\n",
      "Epoch 184/200\n",
      "520/520 [==============================] - 2s - loss: 1.0748 - acc: 0.5731 - val_loss: 1.8375 - val_acc: 0.3144\n",
      "Epoch 185/200\n",
      "520/520 [==============================] - 2s - loss: 1.0604 - acc: 0.5192 - val_loss: 1.7573 - val_acc: 0.3409\n",
      "Epoch 186/200\n",
      "520/520 [==============================] - 2s - loss: 1.0959 - acc: 0.5365 - val_loss: 1.8095 - val_acc: 0.3258\n",
      "Epoch 187/200\n",
      "520/520 [==============================] - 2s - loss: 1.0770 - acc: 0.5769 - val_loss: 1.7974 - val_acc: 0.3182\n",
      "Epoch 188/200\n",
      "520/520 [==============================] - 2s - loss: 1.0498 - acc: 0.5442 - val_loss: 1.7395 - val_acc: 0.3447\n",
      "Epoch 189/200\n",
      "520/520 [==============================] - 2s - loss: 1.0887 - acc: 0.5308 - val_loss: 1.7237 - val_acc: 0.3371\n",
      "Epoch 190/200\n",
      "520/520 [==============================] - 2s - loss: 1.0737 - acc: 0.5365 - val_loss: 1.8096 - val_acc: 0.3144\n",
      "Epoch 191/200\n",
      "520/520 [==============================] - 2s - loss: 1.0814 - acc: 0.5635 - val_loss: 1.8211 - val_acc: 0.3333\n",
      "Epoch 192/200\n",
      "520/520 [==============================] - 2s - loss: 1.0701 - acc: 0.5423 - val_loss: 1.7593 - val_acc: 0.3182\n",
      "Epoch 193/200\n",
      "520/520 [==============================] - 2s - loss: 1.0847 - acc: 0.5538 - val_loss: 1.8476 - val_acc: 0.3144\n",
      "Epoch 194/200\n",
      "520/520 [==============================] - 2s - loss: 1.0302 - acc: 0.5538 - val_loss: 1.8185 - val_acc: 0.3258\n",
      "Epoch 195/200\n",
      "520/520 [==============================] - 2s - loss: 1.0303 - acc: 0.5654 - val_loss: 1.8006 - val_acc: 0.3220\n",
      "Epoch 196/200\n",
      "520/520 [==============================] - 2s - loss: 1.0862 - acc: 0.5250 - val_loss: 1.8565 - val_acc: 0.3068\n",
      "Epoch 197/200\n",
      "520/520 [==============================] - 2s - loss: 1.0683 - acc: 0.5346 - val_loss: 1.8113 - val_acc: 0.3182\n",
      "Epoch 198/200\n",
      "520/520 [==============================] - 2s - loss: 1.0532 - acc: 0.5442 - val_loss: 1.7773 - val_acc: 0.3371\n",
      "Epoch 199/200\n",
      "520/520 [==============================] - 2s - loss: 1.0887 - acc: 0.5442 - val_loss: 1.7706 - val_acc: 0.3295\n",
      "Epoch 200/200\n",
      "520/520 [==============================] - 2s - loss: 1.0751 - acc: 0.5462 - val_loss: 1.7926 - val_acc: 0.3030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x6f69be9e8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y_train_trans,batch_size=10, epochs=200, validation_data=(X_test, y_test_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.5596209692232537, 0.30681818181818182]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test_trans, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.identify>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact_manual\n",
    "def identify(testnumber):\n",
    "    print(\"神經網路判斷為：\",result[testnumber])\n",
    "    print(\"正確答案是:\",y_test_trans[testnumber])\n",
    "interact_manual(identify, testnumber=(0,44))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "aceb30109b3542cfabc09a5f2e035459": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
